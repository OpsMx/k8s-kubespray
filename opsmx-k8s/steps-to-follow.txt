Note: Primary requirements for setting up k8s multi-master multi-node/worker cluster with kubespray using Ansible scripts
1. Required hardware environment with ubuntu 18.04 LTS server
	1.1. Master Node : 4 CPU, 16 GB RAM, 20 GB HDD , Ubuntu 18.04 LTS Server - As required number -- or as mentioned in Pre-requisite.txt
	1.2. Worker Node : 8 CPU, 32 GB RAM, 30 GB HDD , Ubuntu 18.04 LTS Server - As required number -- or as mentioned in Pre-requisite.txt
	1.3. NFS/Launch/HAProxy : 2 CPU, 16 GB RAM, 40 GB HDD , Additional storage as per need (500 GB) Ubuntu 18.04 LTS Server - One No. -- or as mentioned in Pre-requisite.txt
2. Required Software/Applications in the Environment
	2.1 : NFS/Launch/HAProxy : Python(version 2.7.15), Python-pip, python-jinja2 and Ansible(version: 2.7.10), python-netaddr and virtualenv
	2.2 : nfs-comman, nfs-kernel-server, kubectl binary, helm v2.13.1 
3. Networking 
	3.1 : All nodes in same network, prefered static IP.
	3.2 : Public IP for HA and Proxy
	3.3 : FQDN and DNS configurations

Steps to configure K8s-Cluster using Ansible Scripts and Kubespray

Step#1: creating passwordless set up
login to a secific user and generate ssh public keys
	$ ssh-keygen -t rsa
	$ cat /home/<user>/.ssh/id_rsa.pub
login to a 'root' user and generate ssh public keys
	$ ssh-keygen -t rsa
	$ cat /root/.ssh/id_rsa.pub	
List out the above generated keys and note down to a file.
Copy the public-key(generated above) into all the machines 
	$ vi .ssh/authorized_keys
	$ vi /root/.ssh/authorized_keys
Test the connectvity among the machines.
	$ ssh -A IPs ( all private IPs, or with hostnames)
In all machines of /etc/hosts update all master and cluster nodes hostnames with IPs
In all machines update /etc/hostname file with its Fully Qualified Domain Name ( like kubemaster1.opsmx.com)
In all machines update /etc/resolv.conf with its DNS server address. ( nameserver < DNS server IP >, search < your domain name > )

Step2: Do git clone opsmx git repo
Execute command : git clone https://github.com/OpsMx/k8s-kubespray

Step3: Execute kubesprayenv.sh script in launch machine then check setting into virtualenv for ansible setup
Note: update node lists with Private IPs of masters and worker nodes
	$ sudo bash k8s-kubespray/opsmx-k8s/kubesprayenv.sh
Source: https://github.com/OpsMx/k8s-kubespray/blob/master/opsmx-k8s/kubesprayenv.sh
Setup Virtual environment to execute ansible
	$ virtualenv ~/ansible
	$ . ~/ansible/bin/activate
	>>>>(ansible) opsmxgcetest@cisco-kubemhanfs:
		
Step4: Install ansible 2.7.10 using pip in virtual environment
	$ sudo pip install ansible==2.7.10
	$ which ansible
	$ export PATH=$PATH:/usr/local/bin/ansible
	
Step5: Update /etc/ansible/hosts file ref: sample_etc_hosts
Source: k8s-kubespray/opsmx-k8s/opsmx-spinnaker/sample_etc_hosts
	   Check all the machines connectivity using ansible ping
	$ ansible -m ping <each node> -- Or can perform it with individual nodes : user will be prompted for acceptance. 
	$ ansible -m ping all
	
Step6: Follow configuration of all the files as below
File1:
Edit the below file: ( Should look like the below )
	k8s-kubespray/kubespray-install/default/group_vars/all/all.yml
	### Update Master & Load Balance IPs with the below keys array:
	### supplementary_addresses_in_ssl_keys		//Public and Private IPs
	ansible_ssh_extra_args: '-o StrictHostKeyChecking=no'
	kubeconfig_localhost: true
	supplementary_addresses_in_ssl_keys: [masternode1_ip masternode2_privateIP masternode3_privateIP]
	
	cloud_provider: gce
	etcd_data_dir: /var/lib/etcd
	bin_dir: /usr/local/bin
	
	loadbalancer_apiserver_localhost: true
	nginx_kube_apiserver_port: 6443
	
	upstream_dns_servers:
	 - 8.8.8.8
	cert_management: scrip
	kube_read_only_port: 10255

File2:
Verify the below things in k8s-kubespray/kubespray-install/default/group_vars/k8s-cluster/addons.yml
Enabling 'helm'.
	helm_enabled: true
	helm_version: v2.13.1

File3:
Ensure the below lines in 'k8s-kubespray/kubespray-install/default/group_vars/k8s-cluster/k8s-cluster.yml'
	manual_dns_server: 1.1.1.1
	### Provide API server IPs with Pubic-IPs
	kube_apiserver_ip: Public IPs of launch and all kube systems IP ( 35.234.23.5 )
Note: If you use more than three DNS server in resolve.conf. Do the update in below file
		k8s-kubespray/kubespray/roles/container-engine/docker/defaults/main.yml
		Change : docker_dns_servers_strict: true ( to false )
Step7: Execute the command 
	$ ansible-playbook k8s-kubespray/kubespray-install/ssh.yml
	$ansible-playbook k8s-kubespray/kubespray-install/haproxy/haproxy.yml
	
Execute Kubespraydeployment-auto.sh script and wait for completion
	$ sudo sh k8s-kubespray/opsmx-k8s/kubespraydeplyment-auto.sh
Source: https://github.com/OpsMx/k8s-kubespray/blob/master/opsmx-k8s/kubespraydeplyment-auto.sh
		
Step8: Execute nfs-auto.sh script and wait for completion
Note: Update node_list in nfs-auto.sh
https://github.com/OpsMx/k8s-kubespray/blob/master/opsmx-k8s/nfs-auto.sh
	$ sudo bash k8s-kubespray/opsmx-k8s/nfs-auto.sh

Step9: Execute efk-installer.sh script and wait for completion
Source: https://github.com/OpsMx/k8s-kubespray/blob/master/kubespray-install/efk/efk-installer.sh
	$ bash k8s-kubespray/kubespray-install/efk/efk-installer.sh

Step10: Prometheous installtion
Source: https://github.com/OpsMx/k8s-kubespray/tree/master/kubespray-install/Prometheus/prometheus-setup
Scripts:
	1. prometheus-auto.sh (Executable file)
	2. clusterRole.yml
	3. config-map.yml
	4. prometheus-deployment.yml
	5. prometheus-service.yml
Note: 
	1. Create a new inventory file 'k8s-hosts' with the hostnames of master and minion nodes.
	2. Update 'config-map.yml' with the below entry for all the nodes:
		- job_name: 'node1'
		  static_configs:
			- targets: ['x.x.x.x:9100'] -- update x.x.x.x with cluster private IPs
Command:
	$ bash k8s-kubespray/kubespray-install/Prometheus/prometheus-setup/prometheus-auto.sh
	
Step11: Grafana
Source: https://github.com/OpsMx/k8s-kubespray/tree/master/kubespray-install/Grafana/grafana-setup
Scripts:
	1. grafana-auto.sh (Executable file)
	2. grafana-deployment.yml
	3. grafana-service.yml
Command: 
	$ bash k8s-kubespray/kubespray-install/Grafana/grafana-setup/grafana-auto.sh	
	
Step12: Ingress-Controller
	Source: https://github.com/OpsMx/k8s-kubespray/tree/master/Ingress-Controller
	Scripts:
		1. ingress-controller-setup.sh
		2. ingress.conf
		3. mandatory.yaml.temp
		4. service-nodeport.yaml.temp
		5. ingress-rules.yaml
	Note:
	1. Update 'ingress.conf' file with the required inputs for namespace & source path.
	2. After installation, update '/etc/haproxy/haproxy.cfg' file in the launch machine with ingress service port.
	   The command, 'kubectl get svc -n ingress-nginx' can be used to know the ingress service port.
	
	Command: bash k8s-kubespray/Ingress-Controller/ingress-controller-setup.sh k8s-kubespray/Ingress-Controller/ingress.conf	
	
Step13: Follow spinnaker installation step and script
Source: https://github.com/OpsMx/k8s-kubespray/tree/master/opsmx-k8s/opsmx-spinnaker 
Source: https://github.com/OpsMx/k8s-kubespray/blob/master/opsmx-k8s/opsmx-spinnaker/opsmx-spinnaker-step.txt


